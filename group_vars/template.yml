---
# Ansible settings
ansible_ssh_port: 22
ansible_ssh_user: 'root'
# ansible_ssh_pass: 'root'
# ansible_sudo_user: 'root'
# ansible_sudo_pass: 'root'
ansible_become: "{% if ansible_ssh_user != 'root' %}yes{% else %}no{% endif %}"

# timezone settings, default is Asia/Shanghai
timezone: 'Asia/Shanghai'

# modprobe:
#   filename: /etc/modules
#   params:
#     - nf_conntrack
#     - nf_conntrack_ipv4
#     - br_netfilter
#     - overlay

# ipvs:
#   filename: /etc/modules
#   params:
#     - ip_vs
#     - ip_vs_rr
#     - ip_vs_wrr
#     - ip_vs_sh

# sysctl:
#   filename: /etc/sysctl.d/100-kubernetes.conf
#   params:
#     net.ipv4.tcp_keepalive_time: 600
#     net.ipv4.tcp_keepalive_intvl: 30
#     net.ipv4.tcp_keepalive_probes: 10
#     net.ipv6.conf.all.disable_ipv6: 1
#     net.ipv6.conf.default.disable_ipv6: 1
#     net.ipv6.conf.lo.disable_ipv6: 1
#     net.ipv4.neigh.default.gc_stale_time: 120
#     net.ipv4.conf.all.rp_filter: 0
#     net.ipv4.conf.default.rp_filter: 0
#     net.ipv4.conf.default.arp_announce: 2
#     net.ipv4.conf.lo.arp_announce: 2
#     net.ipv4.conf.all.arp_announce: 2
#     net.ipv4.ip_forward: 1
#     net.ipv4.tcp_max_tw_buckets: 5000
#     net.ipv4.tcp_syncookies: 1
#     net.ipv4.tcp_max_syn_backlog: 1024
#     net.ipv4.tcp_synack_retries: 2
#     net.bridge.bridge-nf-call-ip6tables: 1
#     net.bridge.bridge-nf-call-iptables: 1
#     net.bridge.bridge-nf-call-arptables: 1
#     net.netfilter.nf_conntrack_max: 2310720
#     fs.inotify.max_user_watches: 89100
#     fs.may_detach_mounts: 1
#     fs.file-max: 52706963
#     fs.nr_open: 52706963
#     vm.swappiness: 0
#     vm.overcommit_memory: 1
#     vm.panic_on_oom: 0
#     net.netfilter.nf_conntrack_tcp_timeout_established: 86400
#     net.netfilter.nf_conntrack_tcp_timeout_close_wait: 3600

kubernetes:
  # project name use for tls directory(/etc/ssl/$project).
  project: kubernetes

  ssl:
    # Certificate validity
    # default: 10 years
    days: 3652
    location: /etc/kubernetes/pki
    # for porxy reserved
    # extension:
    #   - *.xiaomo.io
    #   - 192.168.1.1

  # defaullt: kubernetes
  name: kubernetes

  # cloud support
  cloud: 
    # choose: local aws azure gcp
    #   local: local data center (default)
    #          if ha.vip and ha.mask is defined and Number of master hosts > 1 will install haproxy and keepalived keep HA
    #   aws: Amazon Web Services
    #          if ha.vip and ha.mask is defined will use cloud slb keep HA
    #   azure: azure cloud
    #          if ha.vip and ha.mask is defined will use cloud slb keep HA
    #   gcp: Google Compute Engine
    #          if ha.vip and ha.mask is defined will use cloud slb keep HA
    type: local
    # file: /etc/kubernetes/cloud.conf

  # kube-apiserver HA configuration
  # ha:
  #   vip: 172.16.17.10
  #   mask: 16

  # choose: none flannel calico canals
  #   none: not deployment any network plugin
  #   flannel: will deployment flannel plugin (default)
  #   calico: will deployment calico plugin
  #   canal: will deployment canal plugin
  network: flannel

  settings:
    master_run_pod: false
    PodCIDR: 10.244.0.0/16
    SvcCIDR: 10.96.0.0/12
    SvcIP: 10.96.0.1
    DNSIP: 10.96.0.2
    NodePortRange: 30000-32767
    ClusterDomain: cluster.local

  # etcd parameter configuration
  etcd: 
    datadir: /var/lib/etcd
    initialclustertoken: 'kubernetes'
    initialclusterstate: 'new'
  
  # docker parameter configuration
  docker:
    datadir: /var/lib/docker
    # Convert the json format to yaml
    daemon: 
      exec-opts:
        - "native.cgroupdriver=systemd"
      registry-mirrors:
        - "https://i3jtbyvy.mirror.aliyuncs.com"
      storage-driver: "overlay2"
      storage-opts: 
        - "overlay2.override_kernel_check=true"
      log-driver: "json-file"
      log-opts: 
        max-size: "100m"
        max-file: "5"
      max-concurrent-downloads: 20
      max-concurrent-uploads: 10
      live-restore: true
      debug: true

  # kubelet parameter configuration
  kubelet: 
    bind: 0.0.0.0
    log:
      logLevel: 2
      logDir: /var/log/kubernetes
      logFile: kubelet.log
    pod_infra_container_image: registry.aliyuncs.com/google_containers/pause:3.2
    image_pull_progress_deadline: 2m

  # kube-apiserver parameter configuration
  apiserver: 
    bind: 0.0.0.0
    enable_admission_plugins:
      - AlwaysPullImages
      - ServiceAccount
      - NamespaceLifecycle
      - NodeRestriction
      - LimitRanger
      - PersistentVolumeClaimResize
      - DefaultStorageClass
      - DefaultTolerationSeconds
      - MutatingAdmissionWebhook
      - ValidatingAdmissionWebhook
      - ResourceQuota
      - Priority
      - PodPreset
    authorization_modes:
      - Node
      - RBAC
    log:
      logLevel: 2
      logDir: /var/log/kubernetes
      logFile: kube-apiserver.log

  # kube-scheduler parameter configuration
  scheduler: 
    bind: 0.0.0.0
    log:
      logLevel: 2
      logDir: /var/log/kubernetes
      logFile: kube-scheduler.log

  # kube-controller-manager parameter configuration
  controllerManager:
    bind: 0.0.0.0
    terminatedPodGcThreshold: 12500
    nodeStatusUpdate: Medium
    log:
      logLevel: 2
      logDir: /var/log/kubernetes
      logFile: kube-controller-manager.log

  # kube-proxy parameter configuration
  proxy:
    log:
      logLevel: 2
      logDir: /var/log/kubernetes
      logFile: kube-proxy.log

  addon:
    # not support
    # metrics_server_enabled: false
    # ingress_nginx_enabled: false
    location: /etc/kubernetes/addon
    image: 
      coredns: coredns/coredns:1.6.9
      flannel: quay.io/coreos/flannel:v0.12.0
      canal:
        node: calico/node:v3.13.2
        flannel: quay.io/coreos/flannel:v0.11.0
        cni: calico/cni:v3.13.2
        flexvol: calico/pod2daemon-flexvol:v3.13.2
      calico: 
        node: calico/node:v3.13.2
        cni: calico/cni:v3.13.2
        typha: quay.io/calico/typha:v3.1.7
        flexvol: calico/pod2daemon-flexvol:v3.13.2
        controllers: calico/kube-controllers:v3.13.2
